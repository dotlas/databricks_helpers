{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d08046ea-5af6-4d2e-9bfb-483adbd72f55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Workspace Migration ✈️\n",
    "\n",
    "## Requirements\n",
    "\n",
    "### Databricks\n",
    "\n",
    "* Two Databricks Workspaces & Workspace Access Tokens for the same\n",
    "* At least one runnable cluster within any workspace\n",
    "\n",
    "> Note: The word `job` and `wokflow` is used interchangeably throughout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae8da7c-d1f1-4f52-ac7e-28c1b1e686e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef603a0-00df-4319-b7eb-0ff8f3bbbeb9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Steps 📊\n",
    "\n",
    "\n",
    "### 1. Fetch workflow / cluster configurations 📬\n",
    "\n",
    "We fetch all the workflows/clusters present in your workspace, each fetched workflow config will also contain the individual task config present in the workflow and their respective job cluster configs.  \n",
    "\n",
    "### 2. Parse Information 🧩\n",
    "\n",
    "In this step we parse the obtained config info. The main thing to keep in mind is that the cluster config contains some fields which are populated after the cluster is initialized but will be fetched anyway from step 1, we need to remove this field or else when we use the same config to create the workflow later it will throw an error. You can also add any custom logic here. For example: You can include webhook notification ID to be associated with a workflow you like, You can also associate an existing all-purpose-compute to a workflow that you want, etc.  \n",
    "\n",
    "### 3. Create new workflow / config 👶🏽\n",
    "\n",
    "Using the parsed info we create workflows/clusters in the new workspace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f517d5d-b817-4e75-85d6-5de5b317bbf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Set up workspace urls and access tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2688c9e-f89c-4b7b-b84c-913016163080",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.removeAll()\n",
    "\n",
    "dbutils.widgets.text(\"old_workspace_url\", \"\")\n",
    "old_workspace_url: str = getArgument(\"old_workspace_url\")\n",
    "\n",
    "dbutils.widgets.text(\"old_workspace_token\", \"\")\n",
    "old_workspace_token: str = getArgument(\"old_workspace_token\")\n",
    "\n",
    "dbutils.widgets.text(\"new_workspace_url\", \"\")\n",
    "new_workspace_url: str = getArgument(\"new_workspace_url\")\n",
    "\n",
    "dbutils.widgets.text(\"new_workspace_token\", \"\")\n",
    "new_workspace_token: str = getArgument(\"new_workspace_token\")\n",
    "\n",
    "\n",
    "query_params = {\n",
    "    \"LIST_JOBS_LIMIT\": 100,  # max limit\n",
    "    \"EXPAND_TASKS\": \"true\",  # provides the complete config info for each job\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dae11b4-39ad-4229-9c06-de60b96a770f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def paginate(\n",
    "    can_paginate: bool,\n",
    "    next_page_token: Optional[str],\n",
    "    url: str,\n",
    "    workspace_token: str,\n",
    "    function_to_call: Callable,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Paginates to the next page if possible\n",
    "    input:\n",
    "        can_paginate [bool]: Boolean info about wheather there is additional info.\n",
    "        next_page_token [str]: Token needed in url query param to paginate to next page.\n",
    "        url [str]: Url used to list the needed info.\n",
    "        function_to_call [Callable]: Function that gets called with the paginated url to paginate further.\n",
    "    output:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if next_page_token and can_paginate:\n",
    "        if \"&page_token\" in url:\n",
    "            url = f\"{url[:url.find('&page_token')]}&page_token={next_page_token}\"\n",
    "        else:\n",
    "            url = f\"{url}&page_token={next_page_token}\"\n",
    "\n",
    "        function_to_call(url, workspace_token)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a11f70f-5c0d-41b6-92f7-74684f5a606a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## List Clusters \n",
    "#### Fetches all clusters in current workspace and its respective configs\n",
    "<a href=\"https://docs.databricks.com/api/workspace/clusters/list\">API Docs</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dece1e7-42d3-437a-a375-f56cc87b9074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getAllClusters(list_clusters_url: str, workspace_token: str) -> None:\n",
    "    \"\"\"\n",
    "    Fetches all the clusters and metadata about them.\n",
    "    input:\n",
    "        list_clusters_url [str]: Databricks API used to fetch all the clusters.\n",
    "        workspace_token [str]: Databricks workspace access token.\n",
    "    output:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(\n",
    "        list_clusters_url,\n",
    "        headers={\"Authorization\": f\"Bearer {workspace_token}\"},\n",
    "    )\n",
    "    assert response.status_code == 200\n",
    "\n",
    "    response_data = response.json()\n",
    "\n",
    "    for cluster_info in response_data.get(\"clusters\", []):\n",
    "        clusters.append(cluster_info)\n",
    "\n",
    "    paginate(\n",
    "        response_data.get(\"has_more\", False),\n",
    "        response_data.get(\"next_page_token\"),\n",
    "        list_clusters_url,\n",
    "        workspace_token,\n",
    "        getAllClusters,\n",
    "    )\n",
    "\n",
    "\n",
    "clusters = []  # holds all cluster' info\n",
    "List_clusters_url = str(old_workspace_url + \"/api/2.0/clusters/list\")\n",
    "getAllClusters(List_clusters_url, old_workspace_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "804512f8-b360-4ca3-8d85-6f63a8ae235d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Filter and Parse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8134e80d-8207-45ca-adab-9314791403ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filterClusters(cluster_info: dict) -> bool:\n",
    "    \"\"\"Filter clusters based on custom logic\"\"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "def parseClusters(cluster_info: dict) -> dict:\n",
    "    \"\"\"Modefies the cluster config.\n",
    "    input:\n",
    "        cluster_info [dict]: Dict containing all the config info about the cluster.\n",
    "    output:\n",
    "        dict : parsed result in accordance with the `create cluster` api payload.\"\"\"\n",
    "    if cluster_info.get(\"aws_attributes\"):\n",
    "        cluster_info.pop(\"aws_attributes\")\n",
    "    if cluster_info.get(\"cluster_id\"):\n",
    "        cluster_info.pop(\"cluster_id\")\n",
    "\n",
    "    # add more custom parsing logic if needed\n",
    "    return cluster_info\n",
    "\n",
    "\n",
    "filtered_clusters = []\n",
    "\n",
    "# filter\n",
    "for cluster_info in clusters:\n",
    "    if filterClusters(cluster_info):\n",
    "        filtered_clusters.append(cluster_info)\n",
    "\n",
    "# parse\n",
    "for idx in range(len(filtered_clusters)):\n",
    "    cluster_info = filtered_clusters[idx]\n",
    "    parsed_cluster_info = parseClusters(cluster_info)\n",
    "    filtered_clusters[idx] = parsed_cluster_info\n",
    "\n",
    "clusters = filtered_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f5dc0e5-e714-43bb-a014-7e55a301119d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create new cluster\n",
    "#### Use the parsed info as payload to create clusters in the new workspace\n",
    "<a href=\"https://docs.databricks.com/api/workspace/clusters/create\">API Docs</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97b639a3-6bd6-4132-9c3b-4802ca5cf73b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for cluster_info in clusters:\n",
    "    response = requests.post(\n",
    "        f\"{new_workspace_url}/api/2.0/clusters/create\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {new_workspace_token}\",\n",
    "        },\n",
    "        data=json.dumps(cluster_info),\n",
    "    )\n",
    "    assert response.status_code in {\n",
    "        200,\n",
    "        201,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1383ed56-7a81-4e91-ae46-a45f59ee65d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## List Workflows \n",
    "#### Fetches all workflows in current workspace and its respective configs\n",
    "<a href=\"https://docs.databricks.com/api/jobs/clusters/list\">API Docs</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ed71bea-8300-4c9a-9601-ed22e50b406c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getAllJobs(list_jobs_url: str, workspace_token: str) -> None:\n",
    "    \"\"\"\n",
    "    Fetches all the jobs and metadata about them.\n",
    "    input:\n",
    "        lists_jobs_url [str]: Databricks API used to fetch all the jobs.\n",
    "        workspace_token [str]: Databricks workspace access token.\n",
    "    output:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(\n",
    "        list_jobs_url,\n",
    "        headers={\"Authorization\": f\"Bearer {workspace_token}\"},\n",
    "    )\n",
    "    assert response.status_code == 200\n",
    "\n",
    "    response_data = response.json()\n",
    "\n",
    "    for job in response_data.get(\"jobs\", []):\n",
    "        jobs.append(job.get(\"settings\"))\n",
    "\n",
    "    paginate(\n",
    "        response_data.get(\"has_more\", False),\n",
    "        response_data.get(\"next_page_token\"),\n",
    "        list_jobs_url,\n",
    "        workspace_token,\n",
    "        getAllJobs,\n",
    "    )\n",
    "\n",
    "\n",
    "jobs = []  # holds all jobs' info\n",
    "List_jobs_url = str(\n",
    "    old_workspace_url\n",
    "    + \"/api/2.1/jobs/list?\"\n",
    "    + f\"limit={query_params.get('LIST_JOBS_LIMIT')}\"\n",
    "    + f\"&expand_tasks={query_params.get('EXPAND_TASKS')}\"\n",
    ")\n",
    "getAllJobs(List_jobs_url, old_workspace_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26d699ee-6076-49aa-bd54-8a5d918936b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Filter and Parse info\n",
    "#### Some of the parsing we can do \n",
    "1. You can add new webhook notif ID \n",
    "2. Tag an existing all-prupose compute to the workflow \n",
    "3. Tag an existing task if the new task (from the workflow) depends on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f8252ae-94e8-4513-9e60-a4b4b62d2054",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filterWorkflows(workflow_info: dict) -> bool:\n",
    "    \"\"\"Filter Workflow based on custom logic\"\"\"\n",
    "    return True\n",
    "\n",
    "\n",
    "def parseWorkflows(workflow_info: dict) -> dict:\n",
    "    \"\"\"Modefies the workflow config.\n",
    "    input:\n",
    "        workflow_info [dict]: Dict containing all the config info about the workflow.\n",
    "    output:\n",
    "        dict : parsed result in accordance with the `create job` api payload.\"\"\"\n",
    "    for cluster_info in workflow_info.get(\n",
    "        \"job_clusters\", []\n",
    "    ):  # below parsing is same for cluster config payload too.\n",
    "        if \"aws_attributes\" in cluster_info.get(\"new_cluster\"):\n",
    "            cluster_info.get(\"new_cluster\").pop(\"aws_attributes\")\n",
    "\n",
    "    # add more custom parsing logic if needed\n",
    "    return workflow_info\n",
    "\n",
    "\n",
    "filtered_jobs = []\n",
    "\n",
    "# filter\n",
    "for workflow_info in jobs:\n",
    "    if filterWorkflows(workflow_info):\n",
    "        filtered_jobs.append(workflow_info)\n",
    "\n",
    "# parse\n",
    "for idx in range(len(filtered_jobs)):\n",
    "    workflow_info = filtered_jobs[idx]\n",
    "    parsed_workflow_info = parseWorkflows(workflow_info)\n",
    "    filtered_jobs[idx] = parsed_workflow_info\n",
    "\n",
    "jobs = filtered_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61459da2-bf71-48eb-9bde-0be70462aa6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create Workflow\n",
    "#### Use the parsed info to create workflow in new workspace\n",
    "<a href=\"https://docs.databricks.com/api/workspace/jobs/create\">API Docs</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "106ec485-e5a3-4dff-a5a9-6e01a68e68b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for workflow_info in jobs:\n",
    "    response = requests.post(\n",
    "        url=f\"{new_workspace_url}/api/2.1/jobs/create\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {new_workspace_token}\",\n",
    "        },\n",
    "        data=json.dumps(workflow_info),\n",
    "    )\n",
    "    assert response.status_code in {\n",
    "        200,\n",
    "        201,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "migrate_workspace",
   "widgets": {
    "new_workspace_token": {
     "currentValue": "",
     "nuid": "47394cf3-4b2e-427e-ab85-7fe7998f33de",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "new_workspace_token",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "new_workspace_url": {
     "currentValue": "",
     "nuid": "efdcc97f-e245-4c68-bca9-992c5489cc0d",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "new_workspace_url",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "old_workspace_token": {
     "currentValue": "",
     "nuid": "f0561168-26a1-434e-af57-8b2405d96362",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "old_workspace_token",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "old_workspace_url": {
     "currentValue": "",
     "nuid": "1dfaf69b-5d6b-4782-bf25-d94605ef9848",
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "old_workspace_url",
      "options": {
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
